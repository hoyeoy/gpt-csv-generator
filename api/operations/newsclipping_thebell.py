import time
from datetime import datetime, timedelta
from urllib.parse import urljoin

import requests
from bs4 import BeautifulSoup
import pandas as pd


def run(params: dict = None) -> pd.DataFrame:
    """
    TheBell ë‰´ìŠ¤ ì‚¬ì´íŠ¸ì—ì„œ ì§€ì •ëœ ë‚ ì§œì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    
    params:
        - days_ago: int (ê¸°ë³¸ê°’ 1, ì–´ì œ ë‚ ì§œ)
    ë°˜í™˜: pandas.DataFrame (URL, Title, Summary ì»¬ëŸ¼ í¬í•¨)
    """
    params = params or {}
    days_ago = params.get("days_ago", 1)
    
    # ğŸ¯ target_date í¬ë§·ì„ 'YYYY-MM-DD'ë¡œ ì„¤ì •
    target_date = (datetime.now() - timedelta(days=days_ago)).strftime("%Y-%m-%d")

    titles, bodies, urls = [], [], []
    page = 1
    max_pages = 5
    headers = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"
        )
    }

    print(f"[{target_date}] The Bell ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘")
    
    while page <= max_pages:
        url = f"https://www.thebell.co.kr/free/content/article.asp?page={page}&svccode=00"
        print(f" Â í˜ì´ì§€ {page}: {url}")

        try:
            resp = requests.get(url, headers=headers, timeout=10)
            resp.raise_for_status()
            soup = BeautifulSoup(resp.text, "html.parser")
            
            # <li> ìš”ì†Œë¥¼ ì°¾ë˜, list_typeì´ë¼ëŠ” í´ë˜ìŠ¤ë¥¼ ê°€ì§„ div ì•ˆì—ì„œë§Œ ì°¾ë„ë¡ ë²”ìœ„ë¥¼ ì¢í˜ (ë” ì•ˆì „í•¨)
            list_container = soup.find('div', class_='list_type') 
            if not list_container:
                print(f" Â í˜ì´ì§€ {page}: ë‰´ìŠ¤ ëª©ë¡ ì»¨í…Œì´ë„ˆ (list_type)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                break
                
            items = list_container.find_all("li")
            if not items:
                print(f" Â í˜ì´ì§€ {page}: ê¸°ì‚¬ í•­ëª©ì´ ì—†ìŒ â†’ ì¢…ë£Œ")
                break
                
            has_target_date_article = False

            for li in items:
                dl = li.find("dl")
                if not dl:
                    continue
                    
                # 1. ë‚ ì§œ ì¶”ì¶œ ë° ë¹„êµ
                date_span = dl.find("span", class_="date")
                if not date_span:
                    continue
                
                date_text = date_span.get_text(strip=True) # ì˜ˆ: "2025-10-29 ì˜¤ì „ 8:14:35"
                
                # 'YYYY-MM-DD'ë¡œ ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸ (ê°€ì¥ í™•ì‹¤í•œ ë¹„êµ)
                if not date_text.startswith(target_date):
                    # target_date ê¸°ì‚¬ê°€ ì•„ë‹ˆë©´, ì´ í˜ì´ì§€ ì´í›„ëŠ” ë” ì˜¤ë˜ëœ ê¸°ì‚¬ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìœ¼ë¯€ë¡œ ë©ˆì¶”ì§€ ì•Šê³  ê³„ì† ì§„í–‰
                    continue

                # 2. ì œëª© ì¶”ì¶œ
                dt = dl.find("dt")
                title = dt.get_text(strip=True) if dt else ""

                # 3. ìš”ì•½ ì¶”ì¶œ
                dd = dl.find("dd")
                body = dd.get_text(strip=True).replace("\n", " ").replace("\r", " ") if dd else ""

                # 4. URL ì¶”ì¶œ ë° ë³€í™˜
                a = dl.find("a")
                href = a.get("href") if a else ""
                full_url = urljoin("https://www.thebell.co.kr/free/content/", href)

                # 5. ë°ì´í„° ì €ì¥
                if title and full_url:
                    titles.append(title)
                    bodies.append(body)
                    urls.append(full_url)
                    has_target_date_article = True
                    print(f" Â  Â â†’ {title}")
                
            # ìµœì í™”: ì´ í˜ì´ì§€ì— target_date ê¸°ì‚¬ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ë‹¤ìŒ í˜ì´ì§€ëŠ” ë” ì˜¤ë˜ëœ ê¸°ì‚¬ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
            if not has_target_date_article and page > 1:
                print(f" Â í˜ì´ì§€ {page} ì´í›„ {target_date} ê¸°ì‚¬ ì—†ìŒ â†’ ì¢…ë£Œ")
                break

            page += 1
            time.sleep(0.7)

        except requests.RequestException as e:
            print(f" Â í˜ì´ì§€ {page} ìš”ì²­ ì˜¤ë¥˜: {e}")
            break
        except Exception as e:
            print(f" Â í˜ì´ì§€ {page} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            break

    # DataFrame ìƒì„±
    df = pd.DataFrame({
        "URL": urls,
        "Title": titles,
        "Summary": bodies
    })

    print(f"ì´ {len(df)}ê°œ ê¸°ì‚¬ ìˆ˜ì§‘ ì™„ë£Œ")
    return df
